{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Although all the of the respective custom implementations are provided in this notebook; however the seperate modules are provided from where the custom models can be imported\n",
    "# from custom_cross_validation_for_probabilistic_classification_algorithms import *\n",
    "# from custom_probabilistic_classification_algorithms import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > (Gaussian) Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBayes:\n",
    "    ''' Implements the Gaussian Bayes For Classification without assuming feature independence. '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.covariances = {}\n",
    "        self.priors = {}\n",
    "        self.classes = []\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        ''' Train the multiclass (or Binary) Bayes Rule using the given \n",
    "            X [m x n] data matrix and Y labels matrix'''\n",
    "\n",
    "        # Getting the unique classes\n",
    "        self.classes = np.unique(Y)\n",
    "        m, n = X.shape\n",
    "\n",
    "        for c in self.classes:\n",
    "            # Selecting the data points belonging to class c\n",
    "            X_c = X[Y == c]\n",
    "\n",
    "            # Calculating the mean for each feature in class c\n",
    "            self.means[c] = np.mean(X_c, axis=0)\n",
    "            \n",
    "            # Calculating the covariance matrix for class c\n",
    "            self.covariances[c] = np.cov(X_c, rowvar=False)\n",
    "            \n",
    "            # Calculating the prior probability for class c\n",
    "            self.priors[c] = X_c.shape[0] / m\n",
    "\n",
    "    def test(self, X):\n",
    "        ''' Run the trained classifiers on the given set of examples \n",
    "            For each example, you should return probability and its assigned class\n",
    "            Input: X of m x d\n",
    "            Output:\n",
    "            pclasses: predicted class of each example\n",
    "            probabilities: probability of each example falling in that predicted class...\n",
    "        '''\n",
    "\n",
    "        m, d = X.shape\n",
    "        pclasses = []\n",
    "        probabilities = np.zeros(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            # Initializing max probability and class\n",
    "            max_prob = -1\n",
    "            best_class = None\n",
    "            \n",
    "            for c in self.classes:\n",
    "                mean = self.means[c]\n",
    "                cov = self.covariances[c]\n",
    "                prior = self.priors[c]\n",
    "                \n",
    "                # Calculating the multivariate Gaussian probability P(X|C)\n",
    "                cov_inv = np.linalg.inv(cov)  # Inverse of covariance matrix\n",
    "                cov_det = np.linalg.det(cov)  # Determinant of covariance matrix\n",
    "                diff = X[i] - mean\n",
    "                \n",
    "                likelihood = (1 / np.sqrt((2 * np.pi) ** d * cov_det)) * \\\n",
    "                             np.exp(-0.5 * np.dot(np.dot(diff.T, cov_inv), diff))\n",
    "                \n",
    "                # Calculating the posterior probability P(C|X)\n",
    "                posterior = likelihood * prior\n",
    "                \n",
    "                # Updating max probability and class\n",
    "                if posterior > max_prob:\n",
    "                    max_prob = posterior\n",
    "                    best_class = c\n",
    "            \n",
    "            # Assigning the best class and its probability\n",
    "            pclasses.append(best_class)\n",
    "            probabilities[i] = max_prob\n",
    "        \n",
    "        return pclasses, probabilities\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' Predicts the class for each example in X '''\n",
    "        \n",
    "        return self.test(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > (Gaussian) Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    ''' Implements the Gaussian Naive Bayes for Classification '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.means = {}\n",
    "        self.variances = {}\n",
    "        self.priors = {}\n",
    "        self.classes = []\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        ''' Train the Gaussian Naive Bayes model using X (features) and Y (labels) '''\n",
    "        \n",
    "        # Getting unique classes from the dataset\n",
    "        self.classes = np.unique(Y)\n",
    "        m, n = X.shape\n",
    "        \n",
    "        for c in self.classes:\n",
    "            # Selecting data points for class c\n",
    "            X_c = X[Y == c]\n",
    "\n",
    "            # Calculating mean and variance for each feature in class c\n",
    "            self.means[c] = np.mean(X_c, axis=0)\n",
    "            self.variances[c] = np.var(X_c, axis=0)\n",
    "\n",
    "            # Calculating prior probability for class c\n",
    "            self.priors[c] = X_c.shape[0] / m\n",
    "        \n",
    "    def test(self, X):\n",
    "        ''' Test the Gaussian Naive Bayes model on input data X\n",
    "            Returns the predicted class and probability for each example '''\n",
    "        \n",
    "        m, d = X.shape\n",
    "        pclasses = []\n",
    "        probabilities = np.zeros(m)\n",
    "\n",
    "        for i in range(m):\n",
    "            max_prob = -1\n",
    "            best_class = None\n",
    "            \n",
    "            for c in self.classes:\n",
    "                # Fetching mean, variance, and prior for class c\n",
    "                mean = self.means[c]\n",
    "                var = self.variances[c]\n",
    "                prior = self.priors[c]\n",
    "                \n",
    "                # Calculating the Gaussian likelihood for each feature\n",
    "                likelihood = np.prod(\n",
    "                    (1 / np.sqrt(2 * np.pi * var)) * \n",
    "                    np.exp(-((X[i] - mean) ** 2) / (2 * var))\n",
    "                )\n",
    "                \n",
    "                # Calculating the posterior probability P(C|X)\n",
    "                posterior = likelihood * prior\n",
    "                \n",
    "                # Checking if this is the best class so far\n",
    "                if posterior > max_prob:\n",
    "                    max_prob = posterior\n",
    "                    best_class = c\n",
    "            \n",
    "            # Storing the best class and its probability\n",
    "            pclasses.append(best_class)\n",
    "            probabilities[i] = max_prob\n",
    "        \n",
    "        return pclasses, probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' Predicts the class for each example in X '''\n",
    "        \n",
    "        return self.test(X)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    ''' Implements the K-Nearest Neighbors (KNN) algorithm for classification '''\n",
    "\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        ''' Store the training data for the KNN classifier '''\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = Y\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        ''' Calculate the Euclidean distance between two points '''\n",
    "        \n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def classify(self, X_test_instance):\n",
    "        ''' Classify a single test instance using the KNN algorithm '''\n",
    "\n",
    "        # Computing all Euclidean distances between X_test_instance and X_train\n",
    "        distances = np.array([self.euclidean_distance(X_test_instance, x_train_instance) \n",
    "                              for x_train_instance in self.X_train])\n",
    "\n",
    "        # Finding the indices of the k smallest distances\n",
    "        k_nearest_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Getting the labels of the k nearest neighbors\n",
    "        k_nearest_labels = self.y_train[k_nearest_indices]\n",
    "\n",
    "        # Performing majority voting\n",
    "        unique_labels, label_counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "\n",
    "        # Returning the label with the highest count (vote)\n",
    "        majority_vote_label = unique_labels[np.argmax(label_counts)]\n",
    "\n",
    "        return majority_vote_label\n",
    "\n",
    "    def test(self, X):\n",
    "        ''' Predict the class for each instance in X '''\n",
    "\n",
    "        predictions = [self.classify(X_test_instance) for X_test_instance in X]\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' Alias for the test method '''\n",
    "\n",
    "        return self.test(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Utility Functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, split_ratio):\n",
    "    ''' Split the data into training and testing sets based on the split ratio '''\n",
    "\n",
    "    total_number_of_samples = len(X)\n",
    "    train_len = int(total_number_of_samples * split_ratio)\n",
    "    X_train = X[:train_len]\n",
    "    X_test = X[train_len:]\n",
    "    y_train = y[:train_len]\n",
    "    y_test = y[train_len:]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_dataset(file_name, extension):\n",
    "    '''Load the dataset using pandas based on the file extension'''\n",
    "\n",
    "    if extension == 'csv':\n",
    "        return pd.read_csv(file_name)\n",
    "    elif extension == 'xlsx':\n",
    "        return pd.read_excel(file_name)\n",
    "    elif extension == 'json':\n",
    "        return pd.read_json(file_name)\n",
    "    elif extension == 'html':\n",
    "        return pd.read_html(file_name)[0]\n",
    "    else:\n",
    "        print(\"Unsupported file extension. Please provide a valid format.\")\n",
    "    \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Driver Code_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Step 1: Upload the dataset\n",
      "\n",
      "Dataset loaded successfully.\n",
      "\n",
      "> Step 2: Split the data into training and testing sets\n",
      "\n",
      "Data has been split successfully.\n",
      "\n",
      "> Step 3: Choose a probabilistic model for classification\n",
      ">> 1. Gaussian Bayes Classifier\n",
      ">> 2. Gaussian Naive Bayes Classifier\n",
      ">> 3. K-Nearest Neighbors Classifier\n",
      "\n",
      "Training and testing Gaussian Bayes Classifier...\n",
      "\n",
      "Accuracy: 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n> Step 1: Upload the dataset\")\n",
    "    extension = input(\"Please, input the file extension (csv, xlsx, json, html): \").strip().lower()\n",
    "    file_name = input(\"\\nEnter the dataset file name (no need to include the extension): \")\n",
    "    dataset = load_dataset(f\"{file_name}.{extension}\", extension)\n",
    "    \n",
    "    if dataset is None:\n",
    "        print(\"\\nFailed to load the dataset. Exiting the program.\")\n",
    "\n",
    "        exit()\n",
    "    \n",
    "    print(\"\\nDataset loaded successfully.\\n\")\n",
    "    print(\"> Step 2: Split the data into training and testing sets\")\n",
    "    split_ratio = float(input(\"\\nEnter the train-test split ratio (0.0 to 1.0): \").strip())\n",
    "    \n",
    "    if not (0.0 < split_ratio < 1.0):\n",
    "        print(\"\\nInvalid split ratio. It must be between 0.0 and 1.0.\")\n",
    "\n",
    "        exit()\n",
    "    \n",
    "    # Assuming last column is the target column\n",
    "    X = dataset.iloc[:, 1:-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, split_ratio)\n",
    "    \n",
    "    print(\"\\nData has been split successfully.\\n\")\n",
    "    print(\"> Step 3: Choose a probabilistic model for classification\")\n",
    "    print(\">> 1. Gaussian Bayes Classifier\")\n",
    "    print(\">> 2. Gaussian Naive Bayes Classifier\")\n",
    "    print(\">> 3. K-Nearest Neighbors Classifier\")\n",
    "    choice = int(input(\"\\nEnter the number corresponding to your choice: \").strip())\n",
    "    \n",
    "    if choice == 1:\n",
    "        print(\"\\nTraining and testing Gaussian Bayes Classifier...\")\n",
    "        model = GaussianBayes()\n",
    "        \n",
    "        model.train(X_train, y_train)\n",
    "        y_pred, _ = model.predict(X_test)\n",
    "\n",
    "        print (f\"\\nAccuracy: {np.sum(y_pred==y_test)/float(y_test.shape[0])}\")\n",
    "    elif choice == 2:\n",
    "        print(\"\\nTraining and testing Gaussian Naive Bayes Classifier...\")\n",
    "        model = GaussianNaiveBayes()\n",
    "\n",
    "        model.train(X_train, y_train)\n",
    "        y_pred, _ = model.predict(X_test)\n",
    "\n",
    "        print (f\"\\nAccuracy: {np.sum(y_pred==y_test)/float(y_test.shape[0])}\")\n",
    "    elif choice == 3:\n",
    "        k = int(input(\"\\nEnter the value of k for KNN: \").strip())\n",
    "        print(\"\\nTraining and testing K-Nearest Neighbors Classifier...\")\n",
    "        model = KNearestNeighbors(k)\n",
    "        \n",
    "        model.train(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = np.mean(y_pred == y_test)\n",
    "\n",
    "        print(f\"\\nAccuracy: {accuracy}\")\n",
    "    else:\n",
    "        print(\"Invalid choice. Exiting the program.\")\n",
    "        \n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _For, Testing and Debugging_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "X = iris_dataset.iloc[:, 1:-1].values\n",
    "y = iris_dataset.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.7)\n",
    "\n",
    "# model = GaussianBayes()\n",
    "# model = GaussianNaiveBayes()\n",
    "model = KNearestNeighbors()\n",
    "\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# y_pred, _ = model.test(X_test)\n",
    "y_pred = model.test(X_test)\n",
    "\n",
    "# print (f\"Accuracy: {np.sum(y_pred==y_test)/float(y_test.shape[0])}\")\n",
    "print(f\"Accuracy: {(np.mean(y_pred == y_test)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > (Simple) K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFoldCV:\n",
    "\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def split(self, X, y):\n",
    "        \"\"\"\n",
    "        Splits the data into k folds.\n",
    "        \"\"\"\n",
    "\n",
    "        num_samples = X.shape[0]\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        fold_size = num_samples // self.k\n",
    "        folds = []\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            start_index = i * fold_size\n",
    "            end_index = start_index + fold_size if i != self.k - 1 else num_samples\n",
    "            fold_indices = indices[start_index:end_index]\n",
    "            folds.append(fold_indices)\n",
    "\n",
    "        return folds\n",
    "\n",
    "    def train_test_split(self, X, y, fold):\n",
    "        \"\"\"\n",
    "        Splits the data into training and testing sets based on the fold.\n",
    "        \"\"\"\n",
    "\n",
    "        test_indices = fold\n",
    "        train_indices = np.array([i for i in range(X.shape[0]) if i not in test_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def cross_validate(self, X, y, model):\n",
    "        \"\"\"\n",
    "        Performs k-fold cross-validation on the given model.\n",
    "        \"\"\"\n",
    "        folds = self.split(X, y)\n",
    "        scores = []\n",
    "\n",
    "        for fold in folds:\n",
    "            X_train, y_train, X_test, y_test = self.train_test_split(X, y, fold)\n",
    "            model.train(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            scores.append(np.mean(predictions == y_test))\n",
    "\n",
    "        return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Stratified K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedKFoldCV:\n",
    "\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "\n",
    "    def split(self, X, y):\n",
    "        \"\"\"\n",
    "        Splits the data into k stratified folds, ensuring that each fold has\n",
    "        a similar distribution of class labels as the original dataset.\n",
    "        \"\"\"\n",
    "    \n",
    "        num_samples = X.shape[0]\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "        class_indices = {cls: np.where(y == cls)[0] for cls in unique_classes}\n",
    "        \n",
    "        # Shuffling class indices to randomize the data within each class\n",
    "        for cls in unique_classes:\n",
    "            np.random.shuffle(class_indices[cls])\n",
    "        \n",
    "        folds = [[] for _ in range(self.k)]\n",
    "        \n",
    "        # Distributing samples across folds while maintaining class proportions\n",
    "        for cls in unique_classes:\n",
    "            cls_indices = class_indices[cls]\n",
    "            fold_size = len(cls_indices) // self.k\n",
    "            \n",
    "            for i in range(self.k):\n",
    "                start_index = i * fold_size\n",
    "                end_index = start_index + fold_size if i != self.k - 1 else len(cls_indices)\n",
    "                fold_indices = cls_indices[start_index:end_index]\n",
    "                folds[i].extend(fold_indices)\n",
    "        \n",
    "        folds = [np.array(fold) for fold in folds]\n",
    "        \n",
    "        return folds\n",
    "\n",
    "    def train_test_split(self, X, y, fold):\n",
    "        \"\"\"\n",
    "        Splits the data into training and testing sets based on the fold.\n",
    "        \"\"\"\n",
    "        \n",
    "        test_indices = fold\n",
    "        train_indices = np.array([i for i in range(X.shape[0]) if i not in test_indices])\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def cross_validate(self, X, y, model):\n",
    "        \"\"\"\n",
    "        Performs stratified k-fold cross-validation on the given model.\n",
    "        \"\"\"\n",
    "        \n",
    "        folds = self.split(X, y)\n",
    "        scores = []\n",
    "\n",
    "        for fold in folds:\n",
    "            X_train, y_train, X_test, y_test = self.train_test_split(X, y, fold)\n",
    "            model.train(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            scores.append(np.mean(predictions == y_test))\n",
    "\n",
    "        return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Driver Code_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Step 5: Choose the cross-validation method\n",
      "\n",
      "> Step 6: Performing cross-validation...\n",
      "\n",
      "Cross-validation results:\n",
      "> Mean accuracy: 0.9600\n",
      "> Standard deviation: 0.0163\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"> Step 5: Choose the cross-validation method\")\n",
    "    cv_method = input(\"Enter 'k' for K-Fold or 's' for Stratified K-Fold: \").strip().lower()\n",
    "\n",
    "    k = int(input(\"\\nEnter the number of folds (k): \"))\n",
    "\n",
    "    if cv_method == 'k':\n",
    "        cv = KFoldCV(k)\n",
    "    elif cv_method == 's':\n",
    "        cv = StratifiedKFoldCV(k)\n",
    "    else:\n",
    "        print(\"\\nInvalid cross-validation method selected.\")\n",
    "\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n> Step 6: Performing cross-validation...\")\n",
    "    mean_score, std_score = cv.cross_validate(X, y, model)\n",
    "\n",
    "    print(f\"\\nCross-validation results:\\n> Mean accuracy: {mean_score:.4f}\\n> Standard deviation: {std_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparitive Analysis of the Custom and _Sklearn_ Based Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Utility Functions_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_cv(model, cv, X, y):\n",
    "    \"\"\"\n",
    "    Run cross-validation with a custom model and custom CV.\n",
    "    \"\"\"\n",
    "    mean_score, std_score = cv.cross_validate(X, y, model)\n",
    "    \n",
    "    return mean_score, std_score\n",
    "\n",
    "def run_sklearn_cv(model, cv, X, y):\n",
    "    \"\"\"\n",
    "    Run cross-validation using sklearn's cross-validation methods.\n",
    "    \"\"\"\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in cv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        scores.append(np.mean(predictions == y_test))\n",
    "\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def compare_classifiers(custom_model, sklearn_model, custom_cv, sklearn_cv, X, y):\n",
    "    \"\"\"\n",
    "    Compare custom and sklearn classifiers using both custom and sklearn CV.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n> Step 5: Comparative Analysis Results:\\n\")\n",
    "    \n",
    "    print(\">> Classification Reports:\")\n",
    "    print(\"Custom Model Classification Report:\")\n",
    "    custom_model.train(X, y)\n",
    "    y_pred_custom = np.array(custom_model.predict(X))  # Assuming custom model is trained on full dataset\n",
    "    print(metrics.classification_report(y, y_pred_custom))\n",
    "\n",
    "    print(\"\\nSklearn Model Classification Report:\")\n",
    "    sklearn_model.fit(X, y)  # Train sklearn model on full dataset\n",
    "    y_pred_sklearn = sklearn_model.predict(X)\n",
    "    print(metrics.classification_report(y, y_pred_sklearn))\n",
    "\n",
    "    # # For, testing\n",
    "    # print(type(y_pred_custom))\n",
    "    # print(type(y_pred_sklearn))\n",
    "    # print(y_pred_custom.shape)\n",
    "    # print(y_pred_sklearn.shape)\n",
    "\n",
    "    print(\"\\n>> Cross Validation Results:\")\n",
    "    custom_mean, custom_std = run_custom_cv(custom_model, custom_cv, X, y)\n",
    "    print(f\"Custom Model - Custom CV: Mean Score = {custom_mean:.4f}, Std Score = {custom_std:.4f}\")\n",
    "\n",
    "    sklearn_mean, sklearn_std = run_sklearn_cv(sklearn_model, sklearn_cv, X, y)\n",
    "    print(f\"Sklearn Model - Sklearn CV: Mean Score = {sklearn_mean:.4f}, Std Score = {sklearn_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Step 1: Upload the dataset\n",
      "\n",
      "Dataset loaded successfully.\n",
      "\n",
      "> Step 2: Split the data into training and testing sets\n",
      "\n",
      "Data has been split successfully.\n",
      "\n",
      "> Step 3: Choose the cross-validation method\n",
      "> Step 4: Choose a probabilistic model for classification\n",
      ">> 1. Gaussian Bayes Classifier\n",
      ">> 2. Gaussian Naive Bayes Classifier\n",
      ">> 3. K-Nearest Neighbors Classifier\n",
      "\n",
      "> Step 5: Comparative Analysis Results:\n",
      "\n",
      ">> Classification Reports:\n",
      "Custom Model Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.94      0.94      0.94        50\n",
      " Iris-virginica       0.94      0.94      0.94        50\n",
      "\n",
      "       accuracy                           0.96       150\n",
      "      macro avg       0.96      0.96      0.96       150\n",
      "   weighted avg       0.96      0.96      0.96       150\n",
      "\n",
      "\n",
      "Sklearn Model Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.94      0.94      0.94        50\n",
      " Iris-virginica       0.94      0.94      0.94        50\n",
      "\n",
      "       accuracy                           0.96       150\n",
      "      macro avg       0.96      0.96      0.96       150\n",
      "   weighted avg       0.96      0.96      0.96       150\n",
      "\n",
      "\n",
      ">> Cross Validation Results:\n",
      "Custom Model - Custom CV: Mean Score = 0.9667, Std Score = 0.0189\n",
      "Sklearn Model - Sklearn CV: Mean Score = 0.9533, Std Score = 0.0094\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n> Step 1: Upload the dataset\")\n",
    "    extension = input(\"Please, input the file extension (csv, xlsx, json, html): \").strip().lower()\n",
    "    file_name = input(\"\\nEnter the dataset file name (no need to include the extension): \")\n",
    "    dataset = load_dataset(f\"{file_name}.{extension}\", extension)\n",
    "    \n",
    "    if dataset is None:\n",
    "        print(\"\\nFailed to load the dataset. Exiting the program.\")\n",
    "\n",
    "        exit()\n",
    "    \n",
    "    print(\"\\nDataset loaded successfully.\\n\")\n",
    "    print(\"> Step 2: Split the data into training and testing sets\")\n",
    "    split_ratio = float(input(\"\\nEnter the train-test split ratio (0.0 to 1.0): \").strip())\n",
    "    \n",
    "    if not (0.0 < split_ratio < 1.0):\n",
    "        print(\"\\nInvalid split ratio. It must be between 0.0 and 1.0.\")\n",
    "\n",
    "        exit()\n",
    "    \n",
    "    # Assuming last column is the target column\n",
    "    X = dataset.iloc[:, 1:-1].values\n",
    "    y = dataset.iloc[:, -1].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, split_ratio)\n",
    "    \n",
    "    print(\"\\nData has been split successfully.\\n\")\n",
    "\n",
    "    print(\"> Step 3: Choose the cross-validation method\")\n",
    "    cv_method = input(\"Enter 'k' for K-Fold or 's' for Stratified K-Fold: \").strip().lower()\n",
    "    k = int(input(\"\\nEnter the number of folds (k): \"))\n",
    "\n",
    "    if cv_method == 'k':\n",
    "        custom_cv = KFoldCV(k)\n",
    "        sklearn_cv = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    elif cv_method == 's':\n",
    "        custom_cv = StratifiedKFoldCV(k)\n",
    "        sklearn_cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        print(\"\\nInvalid cross-validation method selected.\")\n",
    "\n",
    "        exit()\n",
    "\n",
    "    print(\"> Step 4: Choose a probabilistic model for classification\")\n",
    "    print(\">> 1. Gaussian Bayes Classifier\")\n",
    "    print(\">> 2. Gaussian Naive Bayes Classifier\")\n",
    "    print(\">> 3. K-Nearest Neighbors Classifier\")\n",
    "    choice = int(input(\"\\nEnter the number corresponding to your choice: \").strip())\n",
    "\n",
    "    if choice == 1:\n",
    "        custom_model = GaussianNaiveBayes()\n",
    "        sklearn_model = GaussianNB()\n",
    "    elif choice == 2:\n",
    "        custom_model = n_neighbors = int(input(\"Enter the number of neighbors for KNN: \"))\n",
    "        KNearestNeighbors(k)\n",
    "        sklearn_model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    else:\n",
    "        print(\"\\nInvalid classifier selected.\")\n",
    "\n",
    "        exit()\n",
    "\n",
    "    compare_classifiers(custom_model, sklearn_model, custom_cv, sklearn_cv, X, y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
